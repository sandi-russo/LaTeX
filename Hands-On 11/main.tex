\documentclass[a4paper, 12pt]{scrartcl} % Classe KOMA-Script
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsthm} % Per le definizioni
\usepackage{newtxtext, newtxmath} % Font New TX
\usepackage[main=italian, english]{babel}
\usepackage{graphicx}
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=green]{hyperref} % Opzioni Hyperref migliorate
\usepackage{listings} % Per il codice
\usepackage{xcolor}   % Per i colori
\usepackage{amsmath}  % Per la matematica (se serve)
%\usepackage{tikz}     % Includo TikZ anche se non usato direttamente qui
%\usetikzlibrary{positioning, decorations.pathreplacing, shapes.geometric, arrows} % Librerie TikZ
\usepackage{caption}  % Per le didascalie
\usepackage{subcaption} % Per sotto-figure/tabelle (se servono)
\usepackage{geometry} % Per i margini
\geometry{a4paper, margin=2.5cm} % Margini come specificato
\usepackage{multirow} % Per tabelle con celle unite
\usepackage{array}    % Per opzioni avanzate array/tabular
\usepackage{float}    % Per migliorare il posizionamento [H]
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{fontawesome5}
\usetikzlibrary{positioning, shapes.geometric, arrows.meta, decorations.pathreplacing, calc}
\captionsetup{compatibility=false}



\usetikzlibrary{
    shapes.geometric, % Per rombo (diamond)
    positioning,
    arrows.meta 
}


\theoremstyle{definition}
\newtheorem{definizione}{Definizione}[section] % Definizione numerata per sezione


% Definizione colori per listings (come da specifica)
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Impostazioni globali per listings (come da specifica)
\lstset{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue}\bfseries, % Keywords in grassetto blu
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b, % Posizione caption in basso
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single, % Cornice singola
    rulecolor=\color{black},
}


\lstdefinestyle{cstyle}{
    language=C,
    morekeywords={*, extern, static, void, int, return, printf, include, define, ifndef, endif, pthread_t, intptr_t, FILE, NULL, perror, pthread_create, pthread_join, pthread_exit} % Aggiunte keyword C comuni e pthreads
}


\lstdefinestyle{makestyle}{
    language=make,
    keywordstyle=\color{red!80!black}\bfseries, % Diverso colore per Makefile
    morekeywords={*, CC, CFLAGS, LDFLAGS, TARGET, OBJS, SRCS, PHONY, all, clean, check, echo, rm, wildcard, gcc} % Keywords Makefile
}

\begin{document}

% Titolo e autore (modifica con i tuoi dati, usando lo stile richiesto)
\title{Hands-On 11} % Titolo più specifico per HO10
\subtitle{Meccanismi di sincronizzazione} % Sottotitolo specifico
\author{Sandi Russo \\ Corso di Laurea: Scienze Informatiche} % Autore come da esempio
\date{\today} % Usa la data corrente o specifica una data
\maketitle

\newpage
\tableofcontents % Indice dei contenuti
\newpage

\section{Introduzione}
Nel contesto della programmazione concorrente, uno degli aspetti fondamentali è la gestione dell'accesso condiviso alle risorse. Quando più thread operano su variabili o strutture dati comuni, senza una gestione adeguata, possono verificarsi situazioni di \textit{race condition}, che possono portare a comportamenti erratici e difficili da diagnosticare. Per evitare queste problematiche, è necessario utilizzare \textit{meccanismi di sincronizzazione} che permettano un controllo sull'accesso alle risorse condivise. \\
\noindent
Però, prima di indentrarci nel contesto della programmazone concorrente, vorrei riprendere un po' di teoria.
\begin{definizione}
Un \textbf{programma} è un insieme di dati e istruzioni in formato binario (0,1) salvato da qualche parte sul disco. Contiene tutte le informazioni rigurado a un determinato software.
\end{definizione}

\begin{definizione}
    Un \textbf{processo} (\textit{task pesante}) è quello che diventa un programma una volta caricato in memoria. \\
    Ha un \textbf{descrittore di processo} assegnato dal sistema operativo che contiene diverse informazioni: \textit{PID}, \textit{TGID}, l'\textit{indirizzo di memoria}, \textit{tipo di file aperto}, \textit{meccanismi di sicurezza}, \textit{stato di scheduling} e molto altro... 
\end{definizione}

\begin{definizione}
    Un \textbf{Thread} (\textit{task leggero}) è come se fosse un "componente" di un processo. All'interno di un processo, un thread occupa il ruolo di \textbf{esecutore di istruzioni}.
\end{definizione}

\noindent
Di norma, quando un processo si avvia, inzia con un thread (\textbf{main thread}) che prende il codice operativo eseguibil del programma e successivamente, lo esegue. \\
\noindent
Se abbiamo più thread associati a un processo, quando eseguiamo il processo, dobbiamo specificare anche su quale thread eseguire le operazioni.

\subsection{Struttura Thread}
\begin{figure}[ht]
    \centering % Centra l'intera figura

    % Prima sotto-figura
    \begin{subfigure}[c]{0.45\textwidth}
        \centering % Centra il tikzpicture dentro il subfigure
        \begin{tikzpicture}[baseline=(current bounding box.center)]
            \small
            % Contenitore superiore
            \draw (0,0) rectangle (5.5,1.5);
            % Prima riga: Text e Data
            \draw (0.5,1) rectangle (2.5,0.5) node[pos=.5] {Text};
            \draw (3,1) rectangle (5,0.5) node[pos=.5] {Data};
            % Contenitore inferiore
            \draw (0,0) rectangle (5.5,-2);
            % Seconda riga: Registri e Stack
            \node at (1.5,-0.75) {Registri};
            \node at (4,-0.75) {Stack};
            % Terza riga: Thread 0
            \node at (2.75,-1.50) {Thread 0};
        \end{tikzpicture}%
        \caption{Processo \textbf{single thread}}
        \label{subfig:single_thread}
    \end{subfigure}\hfill% Spazio tra le sotto-figure
    % Seconda sotto-figura
    \begin{subfigure}[c]{0.55\textwidth}
        \centering % Centra il tikzpicture dentro il subfigure
        \begin{tikzpicture}[baseline=(current bounding box.center)]
             \small
            % Contenitore superiore
            \draw (0,0) rectangle (9,1.5);
            % Prima riga: Text e Data
            \draw (1,1) rectangle (3.5,0.5) node[pos=.5] {Text};
            \draw (5,1) rectangle (7.5,0.5) node[pos=.5] {Data};
            % Contenitore inferiore
            \draw (0,0) rectangle (9,-4);
            \draw (3,0) rectangle (6,-4);
            % Seconda riga: Registri e Stack
            \node at (1.5,-0.75) {Registri};
            \node at (1.5,-1.25) {Stack};
            \node at (1.5,-3.25) {Thread0};
            \draw (1,-1.75) rectangle (8,-2.75) node[pos=.5] {\textbf{TGID}};
            \node at (4.5,-0.75) {Registri};
            \node at (4.5,-1.25) {Stack};
            \node at (4.5,-3.25) {Thread1};
            \node at (7.5,-0.75) {Registri};
            \node at (7.5,-1.25) {Stack};
            \node at (7.5,-3.25) {Thread2};
        \end{tikzpicture}%
        \caption{Processo \textbf{multi thread}}
        \label{subfig:multi_thread}
    \end{subfigure}

    % Caption generale per l'intera figura
    \caption{Confronto tra strutture di processi single e multi thread.}
    \label{fig:confronto_thread} % Label per l'intera figura

\end{figure}

\noindent
Nel processo multithread, abbiamo più thread in esecuzione \textit{parallela}, dove la struttura de processo è la medesima per \textbf{tutti} i thread; però, ogni thread è "specializzato". Ongi thread ha la sua pila di thread (\textit{stack}) e i suoi registri. Il thread non ha nulla di concorrente.
\newpage
\noindent
Nella programmazione concorrente, possiamo avere un solo thread ed eseguire il nostro codice in serie, oppure, avere \textit{N} thread ed eseguire il codice in parallelo. \\
\noindent
I processi, prendono la loro struttura di segmentazione dal programma che è stato caricato in memoria e che li ha originalmente avviati, mentre i thread, essendo parte di un processo, condivide molto di esso: \textit{spazio di indirizzamento}, \textit{segmento di codice}, \textit{spazio di heap}. \\
\noindent
Dal punto di vista della \textbf{memoria}, i processi sono entità completamente separate l'una dall'altra, mentre i thread accedono all'area di memoria del processo. \\
\noindent
Per quanto riguarda la gestione del sistema operativo: i processo sono trattati come entità \textbf{indipendenti} tra loro e sono anche schedulati indipendentemente in base al loro livello di priorità. \\
\noindent
Per i thread, ci sono due possibilità:
\begin{itemize}
    \item \textit{thread forti}: essere schedulati indipendentemente l'uno con l'altro come entità separate
    \item  \textit{thread deboli}: essere nascosti dallo scheduler e quindi più interni all'applicazione
\end{itemize}

\noindent
Ogni thread ha il suo \textbf{PID} (\textit{process identifier}) e il \textbf{TGID} (\textit{Thread Group Ifentifier}) che serve per raggruppare un insieme di thread che appartengono tutti quanti a uno stesso processo, lo si può notare nella figura \ref{subfig:multi_thread}.\\
\noindent
Sui thread possiamo usare strumenti come le \textbf{primitive di sincronizzazione}, che ci permettono di decidere quale thread avviare prima, quale successivamente e così via... \\
\noindent
In questo lavoro, si è affrontato il problema di gestire l'accesso concorrente a una risorsa condivisa utilizzando diversi metodi di sincronizzazione: il \textit{mutex} e il \textit{semaforo}. Ogni tecnica è stata implementata in un programma che lancia più thread, limitando il numero di thread che possono accedere alla sezione critica contemporaneamente. \\
\noindent
Nel seguito verranno presentati i dettagli del problema, le metodologie utilizzate e i risultati ottenuti dai vari esperimenti, con particolare attenzione alla differenza di comportamento tra l'uso di mutex e semafori.

\section{Definizione del Problema}

Il problema oggetto di studio consiste nella gestione dell'accesso a una risorsa condivisa da parte di più thread, una variabile da incrementare. In un ambiente multithreaded, quando più thread tentano di accedere e modificare una risorsa condivisa, senza alcun controllo, possono insorgere delle condizioni di concorrenza (o "race condition"). Queste condizioni si verificano quando l'ordine di esecuzione dei thread può alterare il risultato finale, introducendo comportamenti imprevisti e difficili da riprodurre.

In questo esercizio sono stati implementati due scenari:
\begin{itemize}
    \item Nel primo, è stato chiesto di permettere l'accesso a due thread alla volta alla sezione critica, utilizzando un semaforo conteggiato per limitare l'accesso.
    \item Nel secondo, l'accesso alla sezione critica è stato protetto da un mutex, che garantisce che solo un thread alla volta possa eseguire la sezione critica.
\end{itemize}

\noindent
L'obiettivo del programma è far sì che i thread possano eseguire in parallelo, ma senza compromettere la consistenza della risorsa condivisa. Ogni thread dovrà incrementare una variabile globale di un valore prefissato e, al termine della sua esecuzione, stampare il suo identificativo e il valore della variabile condivisa.


\section{Metodologia}

Per affrontare il problema di sincronizzazione, sono stati adottati due approcci distinti utilizzando meccanismi di sincronizzazione: il mutex e il semaforo.
 Un \textit{mutex} (mutual exclusion) è stato utilizzato per garantire che solo un thread alla volta possa accedere alla sezione critica, in cui viene modificata una variabile globale. Il mutex è stato inizializzato all'inizio del programma e utilizzato all'interno della sezione critica tramite le operazioni \texttt{pthread\_mutex\_lock()} e \texttt{pthread\_mutex\_unlock()} per proteggere l'accesso concorrente.
    Ogni thread ha incrementato una variabile globale un certo numero di volte. Il risultato finale è stato il valore della variabile al termine di tutte le operazioni di incremento. \\
    \noindent
    Ma cerchiamo di capire come funzina per bene il \textit{mutex}. \\
    \noindent
    Dati due eventi qualsiasi, essi si dicono mutualmente esclusivi se non possono entrambi avvenire allo stesso tempo. L'avvenire di un evento implica il non avvenire dell'altro. \\
    \noindent
    Un esempio può essere il lancio di una moneta dove può uscire testa \textit{o} croce, quindi è un risultato mutualmente esclusivo. \\
    \noindent
    Su un computer, soprattutto su un programma multithread non è fisicamente impossibile che due eventi esclusivi accadano allo stesso momento. È compito dei mutex e dei semafori (\textbf{primitive di sincronizzazione}) assicurare che il nostro codice sia mutualmente esclusivo, indipendentemente dall'ordine di esecuzione e da tutte le variabili dipendenti dal sistema operativo. Se i thread si trovano in una condizione di compezione, si chiama \textbf{race condition}. \\
    \noindent
    Per assicurare la mutua esclusione, bisogna prima identificare una o più \textbf{sezioni critiche}.
    \begin{definizione}
        La \textbf{sezione critica} è una porzione di codice, un insieme di istruzioni che noi vogliamo che venga eseguita in modo mutualmente esclusivo. In parole povere, vogliamo che solo \textit{un thread alla volta} possa eseguire quella porzione di codice, come una variabile condivisa o lettura/scrittura di una risorsa condivisa.
    \end{definizione}
    \noindent
    Una volta identificata la sequenza critica di un programma, implementiamo la mutua esclusione mediante le chiamate delle primitive di tipi di sincronizzazione.
    \noindent
    Prendiamo nuovamente l'esempio dell'incremento della variabile globale condivisa. Senza protezione, un thread potrebbe leggere il valore corrente, essere interrotto dallo scheduler prima di scrivere il nuovo valore, e un secondo thread potrebbe leggere lo *stesso* valore originale, incrementarlo e scriverlo. Quando il primo thread riprende e scrive il suo valore, l'incremento effettuato dal secondo thread viene perso. Questa interleaving non controllata delle operazioni di lettura-modifica-scrittura è la causa principale delle \textbf{race condition}.
    \noindent
    La chiamata \texttt{pthread\_mutex\_lock()} agisce come un cancello: se il mutex è libero (unlocked), il thread lo blocca (locked) e ne diventa il proprietario, potendo così entrare nella sezione critica. Se invece il mutex è già bloccato da un altro thread, il thread chiamante viene sospeso (\textit{bloccato}) dal sistema operativo e messo in una coda di attesa associata a quel mutex. Non consumerà CPU finché il mutex non verrà rilasciato.
    \noindent
    Quando il thread che possiede il mutex esce dalla sezione critica, invoca \texttt{pthread\_mutex\_unlock()}. Questa operazione rilascia il mutex; se ci sono altri thread in attesa su di esso, il sistema operativo ne risveglierà uno (secondo una certa politica di scheduling, es. FIFO) permettendogli di acquisire il lock e procedere. È cruciale notare che, tipicamente, solo il thread che ha bloccato un mutex può sbloccarlo; tentare di sbloccare un mutex non posseduto porta a errori. Questo garantisce che il flusso di controllo attraverso la sezione critica sia strettamente serializzato.
    \noindent
    Tuttavia, l'uso di mutex, specialmente quando un thread necessita di acquisire più di un mutex contemporaneamente (ad esempio per operare su due risorse condivise distinte), introduce il rischio di \textbf{deadlock} (stallo).
\newpage

\begin{tikzpicture}[
    scale=0.9, transform shape,
    node distance=0.8cm and 0.5cm, % Anche queste distanze verranno scalate
    Mutex/.style={
        draw, thick, minimum size=1.2cm, inner sep=1pt, font=\bfseries % Dimensioni e font scalati
    },
    MutexUnlocked/.style={
        Mutex, shape=diamond, label=center:{\faKey}
    },
    MutexLocked/.style={
        Mutex, shape=rectangle
    },
    Thread/.style={
        draw, rectangle, minimum width=1.8cm, minimum height=0.8cm % Dimensioni scalate
    },
    Action/.style={ % Mantenuto below=0cm come da ultimo codice
        font=\small\ttfamily, below=0cm % Font \small scalato
    },
    StepLabel/.style={ % Mantenuto above=-0.1cm come da ultimo codice
        font=\bfseries, above=-0.1cm % Distanza negativa, causerà sovrapposizione
    },
    ArrowStyle/.style={
        -{Stealth[length=2mm]}, thick % Freccia spessa (scalata a 0.9*thick)
    }
]

% --- Step 1 ---
\node[MutexUnlocked] (Mutex1) {a};
\node[StepLabel, above=-0.1cm of Mutex1] (Step1Label) {Step 1};
\node[Thread, below left=of Mutex1] (Thread1Step1) {th1};
\node[Thread, below right=of Mutex1] (Thread2Step1) {th2};
\node[Action, below=0cm of Thread1Step1] (Action1Step1) {mutex\_lock(a)};

% --- Step 2 ---
\node[MutexLocked, below=3.5cm of Mutex1] (Mutex2) {a}; % Distanza 3.5cm scalata
\node[StepLabel, above=-0.1cm of Mutex2] (Step2Label) {Step 2};
% Freccia verticale dall'alto verso Step2Label.north
\draw [ArrowStyle] ([yshift=0.5cm]Step2Label.north) -- (Step2Label.north);
\node[Thread, below left=of Mutex2] (Thread1Step2) {th1~{\small\faKey}};
\node[Thread, below right=of Mutex2] (Thread2Step2) {th2};
\node[Action, below=0cm of Thread2Step2] (Action2Step2) {mutex\_lock(a)};

% --- Step 3 ---
\node[MutexLocked, below=3.5cm of Mutex2] (Mutex3) {a}; % Distanza 3.5cm scalata
\node[StepLabel, above=-0.1cm of Mutex3] (Step3Label) {Step 3};
% Freccia verticale dall'alto verso Step3Label.north
\draw [ArrowStyle] ([yshift=0.5cm]Step3Label.north) -- (Step3Label.north);
\node[Thread, below left=of Mutex3] (Thread1Step3) {th1~{\small\faKey}};
\node[Thread, below right=of Mutex3] (Thread2Step3) {th2~{\small\faHourglassHalf}};
\node[Action, below=0cm of Thread2Step3] (Action3Step3) {mutex\_lock(a)};

% --- Step 4 ---
\node[MutexUnlocked, below=3.5cm of Mutex3] (Mutex4) {a}; % Distanza 3.5cm scalata
\node[StepLabel, above=-0.1cm of Mutex4] (Step4Label) {Step 4};
% Freccia verticale dall'alto verso Step4Label.north
\draw [ArrowStyle] ([yshift=0.5cm]Step4Label.north) -- (Step4Label.north);
\node[Thread, below left=of Mutex4] (Thread1Step4) {th1};
\node[Action, below=0cm of Thread1Step4] (Action4Step1) {mutex\_unlock(a)};
\node[Thread, below right=of Mutex4] (Thread2Step4) {th2~{\small\faHourglassHalf}};
\node[Action, below=0cm of Thread2Step4] (Action4Step2) {mutex\_lock(a)};

% --- Step 5 ---
\node[MutexLocked, below=3.5cm of Mutex4] (Mutex5) {a}; % Distanza 3.5cm scalata
\node[StepLabel, above=-0.1cm of Mutex5] (Step5Label) {Step 5};
% Freccia verticale dall'alto verso Step5Label.north
\draw [ArrowStyle] ([yshift=0.5cm]Step5Label.north) -- (Step5Label.north);
\node[Thread, below left=of Mutex5] (Thread1Step5) {th1};
\node[Thread, below right=of Mutex5] (Thread2Step5) {th2~{\small\faKey}};

% --- Step 6 ---
\node[MutexUnlocked, below=3.5cm of Mutex5] (Mutex6) {a}; % Distanza 3.5cm scalata
\node[StepLabel, above=-0.1cm of Mutex6] (Step6Label) {Step 6};
% Freccia verticale dall'alto verso Step6Label.north
\draw [ArrowStyle] ([yshift=0.5cm]Step6Label.north) -- (Step6Label.north);
\node[Thread, below left=of Mutex6] (Thread1Step6) {th1};
\node[Thread, below right=of Mutex6] (Thread2Step6) {th2};
\node[Action, below=0cm of Thread2Step6] (Action6Step2) {mutex\_unlock(a)};

\node[align=left, anchor=north west, text width=9cm] at ([xshift=1cm]current bounding box.north east) {
    \textbf{Legenda:}\\[0.5em]
    \faKey\quad Mutex posseduto dal thread\\
    \faHourglassHalf\quad Thread in attesa\\
    \faSquare\quad Mutex bloccato\\
    \(\lozenge\)\quad Mutex sbloccato\\[1.5em]
    Questo diagramma mostra l'evoluzione dello stato del mutex \texttt{a} attraverso sei step sequenziali.\\
    Inziamo con il mutex sbloccato, con i rettangoli che rappresentano i thread in esecuzione concorrente. \\
    Il \textit{th1} effettua una chiamata alla primitiva mutex con \textit{mutex\_lock(a)}. In questo caso, il mutex è sbloccato e siamo autorizzati a bloccarlo (Step 1). \\
    Quando il mutex è sbloccato, possiamo immaginare che esista una chiave che era la sua serratura. L'operazione di blocco, chiude la serratura del mutex, tira fuori la chiave e la lascia al thread che ha effettuato la chiamata (Step 2). \\
    IL \textit{th1} ora sta eseguendo la sua \textbf{sezione critica}. Adesso, il \textit{th2} chiama \textbf{mutex\_lock(a)}. Il mutex a, è stato già bloccato da \textit{th1} che ha la chiave e non l'ha ancora rilasciata; di conseguenza, non possiamo rilasciare il mutex nè far proseguire \textit{th2} dato che l'istruzione di lock non può essere eseguita in questo istante. Il \textit{th2} verrà rimosso dall'esecuzione e messo in stato di \textit{attesa} finché il mutex non verrà liberato (Step 3). \\
    Il \textit{th1} finisce l'esecuzione della sua \textbf{sezione critica} e chiama la funzione \textit{mutex\_unclock(a)}, così la chiave torna al mutex che si sblocca (Step 4). \\
    Adesso, lo scheduler risveglia il \textit{th2} (che era in attesa) e, finalmente, il \textit{th2} può prendere la chiave e bloccare il mutex. Ora sarà il \textit{th2} ad eseguire la sua \textbf{sezione critica} (Step 5). \\
    Dopo che finisce la \textbf{sezione critica} richiama la funzione \textit{mutex\_unclock(a)} e sblocca il mutex (Step 6).\\
    Questo è il meccanismo che ha permesso di rendere esclusiva l'esecuzione delle due sezioni critiche.
};

\end{tikzpicture}

\noindent
Adesso, facciamo un esempio con due mutex (\textit{a}, \textit{b}). Le chiavi dei due mutex sono \textbf{diverse}, quindi, se con una chiave ho bloccato il mutex a, non posso usare la medesima chiave per bloccare il mutex b.\\[1em]


\begin{tikzpicture}[
    scale=0.9, transform shape,
    % Distanza V tra righe (mutex->thread), H tra mutex/thread affiancati
    node distance=1cm and 2.5cm,
    Mutex/.style={
        draw, thick, minimum size=1.2cm, inner sep=1pt, font=\bfseries
    },
    % Stili separati per chiavi diverse
    MutexUnlockedA/.style={
        Mutex, shape=diamond, label=center:{\faKey} % Chiave standard per a
    },
    MutexUnlockedB/.style={
        Mutex, shape=diamond, label=center:{\faKeycdn} % Chiave diversa per b
    },
    MutexLocked/.style={
        Mutex, shape=rectangle % Senza chiave
    },
    Thread/.style={
        draw, rectangle, minimum width=1.8cm, minimum height=0.8cm
    },
    Action/.style={ % Azioni attaccate sotto
        font=\small\ttfamily, below=0cm
    },
    StepLabel/.style={ % Etichette sovrapposte sopra
        font=\bfseries, above=-0.1cm % Mantenuto valore negativo richiesto
    },
    ArrowStyle/.style={ % Freccette verso StepLabel
        -{Stealth[length=2mm]}, thick
    }
]

% --- Step 1 ---
% Mutex Row
\node[MutexUnlockedA] (MutexA1) {a};
\node[MutexUnlockedB, right=of MutexA1] (MutexB1) {b};
% Step Label (sopra il primo mutex)
\node[StepLabel, above=-0.1cm of MutexA1, xshift=1.8cm] (Step1Label) {Step 1};
% Thread Row (posizionati sotto i rispettivi mutex per semplicità)
\node[Thread, below=of MutexA1] (Thread1Step1) {th1};
\node[Thread, below=of MutexB1] (Thread2Step1) {th2};
% Action Row
\node[Action, below=0cm of Thread1Step1] (Action1Step1) {mutex\_lock(a)};
\node[Action, below=0cm of Thread2Step1] (Action2Step1) {mutex\_lock(b)};

% --- Step 2 ---
% Definisce la posizione del primo mutex di questo step sotto il primo mutex dello step precedente
\node[MutexLocked, below=3.5cm of MutexA1] (MutexA2) {a}; % Mutex a bloccato
\node[MutexLocked, right=of MutexA2] (MutexB2) {b};      % Mutex b bloccato
% Step Label
\node[StepLabel, above=-0.1cm of MutexA2, xshift=1.8cm] (Step2Label) {Step 2};
\draw [ArrowStyle] ([yshift=0.5cm]Step2Label.north) -- (Step2Label.north);
% Thread Row (con le rispettive chiavi)
\node[Thread, below=of MutexA2] (Thread1Step2) {th1~{\small\faKey}};    % th1 ha chiave a
\node[Thread, below=of MutexB2] (Thread2Step2) {th2~{\small\faKeycdn}}; % th2 ha chiave b

% --- Step 3 ---
\node[MutexUnlockedA, below=3.5cm of MutexA2] (MutexA3) {a}; % Mutex a sbloccato
\node[MutexUnlockedB, right=of MutexA3] (MutexB3) {b};      % Mutex b sbloccato
% Step Label
\node[StepLabel, above=-0.1cm of MutexA3, xshift=1.8cm] (Step3Label) {Step 3};
\draw [ArrowStyle] ([yshift=0.5cm]Step3Label.north) -- (Step3Label.north);
% Thread Row (senza chiavi)
\node[Thread, below=of MutexA3] (Thread1Step3) {th1};
\node[Thread, below=of MutexB3] (Thread2Step3) {th2};
% Action Row
\node[Action, below=0cm of Thread1Step3] (Action1Step3) {mutex\_unlock(a)};
\node[Action, below=0cm of Thread2Step3] (Action2Step3) {mutex\_unlock(b)};

\node[align=left, anchor=north west, text width=9cm] at ([xshift=1cm]current bounding box.north east) {
    \textbf{Legenda:}\\[0.5em]
    \faKey\quad Chiave Mutex a\\
    \faKeycdn\quad Chiave Mutex b \\
    \faHourglassHalf\quad Thread in attesa\\
    \faSquare\quad Mutex bloccato\\
    \(\lozenge\)\quad Mutex sbloccato\\[1.5em]
    Il \textit{th1} blocca il mutex a mentre il \textit{th2} blocca il mutex b (Step 1) \\
    Se il \textit{th1} cercasse di sbloccare il mutex b e viceversa, i mutex ignorerebbero il comando \\
    Se proviamo \textit{mutex\_unlock(x)} sui correspettivi mutex, tutto va come dovrebbe e i mutex si sbloccano. \\
    L'esempio più banale di questo è un sistema multi-utente di bonifici bancari, dove ogni terminale della banca è un thread diverso che eseguirà il codice di sopra. La parte critica è tutto il codice che si occupa di trnasizionare il sistema da uno in cui il sistema è in valido a uno che è valido. In uno stato possiamo avere 10,00€ in più, nel successivo 10,00€ in meno. Questo è noto come atomicità, perché vogliamo che l'operazione venga eseguita del tutto o che si annulli e torni allo stato precedente \textit{rollback}. 
};

\end{tikzpicture}

\begin{definizione}
    Un \textbf{mutex} (\textit{lock} o \textit{semaforo binario}) è una primitiva di sincronizzazione utilizzabile per assicurare la mutua esclusione. Sono un caso particolare dei semafori. Li possiamo vedere come dei blocchi attivabili da un thread alla volta. L'attivazione del blocco è chiamato \textit{lock}, mentre la disattivazione \textit{unlock}.    
\end{definizione}

\begin{definizione}
    Un \textbf{deadlock} è un'attesa infinita, ovvero quando si forma una coda circolare.
\end{definizione}


\tikzset{
    matrix_header/.style={ % Stile per l'intestazione Mutex
        font=\bfseries\large,
        text height=1.5ex, % Assicura altezza minima per allineamento
        text depth=.25ex
    },
    matrix_thread/.style={ % Stile per il nome del thread
        font=\itshape,
        minimum height=2.5ex % Aggiunge un po' di spazio
    },
    matrix_action/.style={ % Stile per le azioni lock/unlock
        font=\small\ttfamily,
        minimum height=2.5ex % Spazio tra le azioni
    }
}

\begin{tikzpicture}
    \matrix (deadlock_scenario) [
        matrix of nodes,      % Ogni cella è un nodo TikZ
        nodes={anchor=center}, % Allinea il testo al centro del nodo/cella
        row sep=3mm,         % Spazio verticale tra le righe (aggiustabile)
        column sep=15mm,      % Spazio orizzontale tra le colonne (aggiustabile)
        ampersand replacement=\& % Usa \& per separare le colonne
    ]
    { % Contenuto della matrice: Riga1 \\ Riga2 \\ ...
      % Riga 1: Intestazioni Mutex
      |[matrix_header]| Mutex a  \&  |[matrix_header]| Mutex b  \\
      % Riga 2: Nomi Thread
      |[matrix_thread]| thread 1 \&  |[matrix_thread]| thread 2 \\
      % Riga 3: Prima Azione
      |[matrix_action]| lock(a)  \&  |[matrix_action]| lock(b)  \\
      % Riga 4: Seconda Azione
      |[matrix_action]| lock(b)  \&  |[matrix_action]| lock(a)  \\
      % Riga 5: Terza Azione
      |[matrix_action]| unlock(b)\&  |[matrix_action]| unlock(a) \\
      % Riga 6: Quarta Azione
      |[matrix_action]| unlock(a)\&  |[matrix_action]| unlock(b) \\
    }; % Fine del contenuto della matrice

\node[align=left, anchor=north west, text width=9cm] at ([xshift=1cm]current bounding box.north east) {
    Se il \textit{th1} blocca mutex a e il \textit{th2} blocca il mutex b, avviene una \textit{deadlock}, perché, nella seconda istruzione quando il \textit{th1} proverà a bloccare mutex b, lo troverò già bloccato e quindi andrà in attesa. \\
    Medesima situazione per \textit{th2} e il mutex a, finirà in attesa. \\
    Ecco che i processi "muoiono" perché non riescono ad andare avanti.
};
\end{tikzpicture}

\subsection{Semaforo}
    Un \textit{semaforo} è stato utilizzato per limitare il numero di thread che possono entrare in sezione critica contemporaneamente. In particolare, il semaforo è stato inizializzato con il valore 2, il che significa che solo due thread possono entrare nella sezione critica alla volta.
    Il semaforo è stato gestito tramite le operazioni \texttt{sem\_wait()} e \texttt{sem\_post()} per sincronizzare i thread e regolare il numero di thread concorrenti.
\noindent
Per entrambe le soluzioni, sono stati creati 5 thread, ognuno dei quali incrementa una variabile globale 10.000 volte. La sincronizzazione tra i thread è stata monitorata per garantire che il risultato finale sia quello atteso, ovvero che la variabile globale sia incrementata correttamente senza errori di concorrenza.
\noindent
In seguito, sono stati creati dei grafici per confrontare i comportamenti dei due approcci (mutex e semaforo), evidenziando differenze in termini di performance e correttezza dell'esecuzione.
\noindent
Noi lavoreremo sulla categoria \textbf{counting semaphore}, sono semafori che hanno un numero intero positivo o negativo, sul quale può essere effettuata un'operazione di incremento o decremento. \\
Un esempio può essere la discoteca è vuota, il buttafuori farà entrare tutte e trenta le persona, una volta piena, il buttafuori bloccherà le persone fuori che rimarranno in fila. \\
Qunado una persona esce dalla discoteca, il buttafuori se ne accorge e fa entrare una persona che era in fila. \\
Il semaforo è rappresentato dal dal buttafuori, il valore del semaforo è rappresentato dal numero di posti liberi all'interno della discoteca e i thread sono le persone in coda o all'interno della discoteca. \\
Il semaforo va inizializzato con un valore a nostro piacimento, dopo averlo inizializzata non possiamo più atterrare quel valore. Possiamo interagire con il semaforo mediante due funzioni che sono le analoghe dei mutex della lock e unlock; le funzioni sono: \textit{sem\_wait()} e \textit{sem\_post()}. \\
Di norma, non possiamo né leggere né scrivere il contenuto del semaforo durante il suo utilizzo. Lo manipoliamo tramite le funzioni esterne. \\
Per inizializzare il semaforo, sfrutteremo la funzione \textbf{sem\_init(s,v)}, dove "s" è il semaforo al quale facciamo riderimento, "v" è il valore iniziale. Adesso, il valore può essere \textbf{v>0} o \textbf{v=0}. Si può anche chiamare rispettivamente \textbf{semaforo "sbloccato"} o \textbf{semaforo "bloccato"}. \\
Se assegnamo \textbf{1} a \textbf{v}, il semaforo si comporterà come un mutex. \\
Nel problema classico del \textbf{produttore-consumatore}, un produttore genera dati e un consumatore li utilizza. I semafori possono \textbf{sincronizzare} questi processi, assicurando che il consumatore attenda finché non ci sono dati disponibili e che il produttore attenda se il buffer è pieno. \\
\noindent % Inizio aggiunta
Analizziamo più nel dettaglio le operazioni fondamentali. La funzione \texttt{sem\_wait(s)} (chiamata anche P, dal termine olandese \textit{proberen}, provare) tenta di decrementare il valore intero del semaforo `s`. Se il valore del semaforo, prima del decremento, è strettamente maggiore di zero, l'operazione ha successo immediato, il valore viene decrementato e il thread prosegue (interpretato come l'acquisizione di una unità di risorsa). Se invece il valore del semaforo è minore o uguale a zero, il thread non può procedere; viene quindi messo in stato di attesa (bloccato) senza decrementare il contatore, tipicamente inserito in una coda associata al semaforo.
\noindent
La funzione \texttt{sem\_post(s)} (chiamata anche V, da \textit{verhogen}, incrementare) incrementa il valore del semaforo `s`. Questa operazione segnala il rilascio di una risorsa o la disponibilità di un nuovo dato. Se, a seguito dell'incremento, il valore del semaforo diventa maggiore di zero (o, in alcune implementazioni, se ci sono thread in attesa), il sistema operativo provvede a sbloccare (risvegliare) uno dei thread precedentemente bloccati sulla `sem\_wait` per quel semaforo. Il thread risvegliato potrà quindi completare la sua operazione `sem\_wait` (che ora troverà un valore positivo da decrementare) e continuare l'esecuzione. A differenza dei mutex, i semafori non hanno un concetto di "proprietà": qualsiasi thread può eseguire `sem\_post` su un semaforo, non solo quello che ha (eventualmente) causato il decremento tramite `sem\_wait`.
\noindent
\\Ritornando al \textbf{produttore-consumatore}, lo schema classico prevede l'uso di due semafori contatori: `empty`, inizializzato alla capacità `N` del buffer (numero di slot vuoti), e `full`, inizializzato a `0` (numero di slot pieni). Il produttore esegue `sem\_wait(empty)` prima di accedere al buffer (attende se non ci sono slot vuoti), inserisce il dato, e poi esegue `sem\_post(full)` (segnala uno slot pieno in più). Il consumatore opera simmetricamente: `sem\_wait(full)` (attende se non ci sono slot pieni), preleva il dato, e poi esegue `sem\_post(empty)` (segnala uno slot vuoto in più). Per proteggere l'accesso effettivo agli indici del buffer durante l'inserimento/prelievo, spesso si aggiunge anche un terzo semaforo, binario (o un mutex), chiamato ad esempio `mutex\_buffer`, usato con `wait` prima dell'accesso e `post` dopo. % Fine aggiunta
\noindent
La \textbf{sem\_post(s)} incrementa il valore del semaforo indipendentemente dal suo stato interno. Se il valore interno passa da 0 a 1 è possibile che i thread che erano in attesa, si risvegliano. Questo può essere visto come il numero di risorse libere nel sistema. Se avevamo 25, passeremo a 26. \\
La \textbf{sem\_wait(s)} decrementa condizionalmente il valore del semaforo. Se il semaforo è bloccato \textbf{v=0}, la chiamata non decrementa immediatamente, ma blocca il thread che esegue la \textit{sem\_wait(s)} che verrà successivamente risvegliato dallo scheduler, solo e se il valore del semaforo diventa \textbf{>0}. \\
Abbiamo richiesto una risorsa ma nel sistema ci sono 0 risorse libere e noi non possiamo andare avanti senza quella risorsa. \\
Se il valore del semaforo è \textbf{>0}, quindi semaforo sbloccato il valore viene decrementato e la funzione ritorna immediatamente. \\
Al massimo può passare da \textbf{1} a \textbf{0} ma bloccare il semaforo è diverso da tentare di decrementare il semaforo a valore 0.

\subsection{Scenario Base: Nessuna Sincronizzazione}
In questo primo scenario, viene mostrato il problema della race condition. Dieci thread vengono creati, e ognuno incrementa una variabile globale `j` per 1000 volte. Non viene utilizzato alcun meccanismo di sincronizzazione.


\begin{lstlisting}[style=cstyle, caption={File function.h (Esercizio 1)}, label={lst:ex1_h}]
#ifndef FUNCTION_H
#define FUNCTION_H

#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h> // Per sys/types.h implicitamente e funzioni POSIX
#include <sys/types.h> // Per tipi come pid_t (anche se non usati direttamente)

#define MAX_THREADS 10
#define MAX_NUM 1000

// Dichiarazione variabile globale (definita in main.c)
extern int j;

// Prototipo funzione eseguita dai thread
void *thread_function (void *arg);

#endif // FUNCTION_H
\end{lstlisting}
\newpage
\begin{lstlisting}[style=cstyle, caption={File main.c (Esercizio 1)}, label={lst:ex1_main}]
#include "function.h"

// Definizione e inizializzazione variabile globale
int j = 0;

int main() {
    pthread_t thread_id[MAX_THREADS];
    int thread_args[MAX_THREADS]; // Array per passare argomenti (ID) ai thread

    // Creazione dei thread
    printf("Creazione di %d thread...\n", MAX_THREADS);
    for (int i = 0; i < MAX_THREADS; i++) {
        thread_args[i] = i; // Assegna un ID univoco per identificazione
        if (pthread_create(&thread_id[i], NULL, thread_function, &thread_args[i]) != 0) {
            perror("Errore nella creazione del thread");
            return 1; // Esce in caso di errore
        }
    }

    // Attesa della terminazione di tutti i thread
    printf("Attesa terminazione thread...\n");
    for (int i = 0; i < MAX_THREADS; i++) {
        if (pthread_join(thread_id[i], NULL) != 0) {
            perror("Errore nell'attesa del thread (join)");
            return 1; // Esce in caso di errore
        }
    }

    // Stampa del valore finale della variabile globale
    // Ci si aspetterebbe MAX_THREADS * MAX_NUM = 10 * 1000 = 10000
    printf("\nTutti i thread hanno terminato.\n");
    printf("Valore finale di j (senza sincronizzazione): %d\n", j);

    return 0; // Termina correttamente
}
\end{lstlisting}

\begin{lstlisting}[style=cstyle, caption={File thread.c (Esercizio 1)}, label={lst:ex1_thread}]
#include "function.h"

// Funzione eseguita da ciascun thread
void *thread_function(void *arg) {
    // Recupera l'ID del thread passato come argomento
    int id = *(int *)arg;

    // Ciclo di incremento della variabile globale condivisa 'j'
    // Questa operazione (j++) NON e' atomica!
    // Si traduce in: leggi j, incrementa registro, scrivi j.
    // L'esecuzione puo' essere interrotta tra queste sotto-operazioni.
    for (int i = 0; i < MAX_NUM; i++) {
        j++; // Operazione critica senza protezione
    }
    return NULL;
}
\end{lstlisting}


\subsubsection{Codice Sorgente (con Mutex)}

\begin{lstlisting}[style=cstyle, caption={File function.h (Esercizio 2 - Mutex)}, label={lst:ex2_h}]
#ifndef FUNCTION_H
#define FUNCTION_H

#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/types.h>

#define MAX_THREADS 10
#define MAX_NUM 1000

// Dichiarazione variabile globale
extern int j;
// Dichiarazione del mutex (variabile globale)
extern pthread_mutex_t lock;

// Prototipo funzione eseguita dai thread
void *thread_function (void *arg);

#endif // FUNCTION_H
\end{lstlisting}

\begin{lstlisting}[style=cstyle, caption={File main.c (Esercizio 2 - Mutex)}, label={lst:ex2_main}]
#include "function.h"

// Definizione variabile globale
int j = 0;
// Definizione variabile mutex globale
pthread_mutex_t lock;

int main() {
    pthread_t thread_id[MAX_THREADS];
    int thread_args[MAX_THREADS];

    // Inizializzazione del mutex (importante!)
    // Il secondo argomento NULL usa gli attributi di default
    if (pthread_mutex_init(&lock, NULL) != 0) {
        perror("Errore nell'inizializzazione del mutex");
        return 1;
    }
    printf("Mutex inizializzato.\n");

    // Creazione dei thread (come prima)
    printf("Creazione di %d thread...\n", MAX_THREADS);
    for (int i = 0; i < MAX_THREADS; i++) {
        thread_args[i] = i;
        if (pthread_create(&thread_id[i], NULL, thread_function, &thread_args[i]) != 0) {
            perror("Errore nella creazione del thread");
            pthread_mutex_destroy(&lock); // Libera il mutex prima di uscire
            return 1;
        }
    }

    // Attesa della terminazione dei thread (come prima)
    printf("Attesa terminazione thread...\n");
    for (int i = 0; i < MAX_THREADS; i++) {
        if (pthread_join(thread_id[i], NULL) != 0) {
            perror("Errore nell'attesa del thread (join)");
            // Potenzialmente altri mutex potrebbero rimanere bloccati,
            // ma cerchiamo comunque di distruggere il nostro.
            pthread_mutex_destroy(&lock);
            return 1;
        }
    }

    // Distruzione del mutex (rilascia le risorse associate)
    if (pthread_mutex_destroy(&lock) != 0) {
        perror("Errore nella distruzione del mutex");
        // Non fatale, ma segnala un problema (es. mutex ancora bloccato?)
    } else {
        printf("Mutex distrutto.\n");
    }

    // Stampa del valore finale. Ora dovrebbe essere corretto.
    // Valore atteso: MAX_THREADS * MAX_NUM = 10 * 1000 = 10000
    printf("\nTutti i thread hanno terminato.\n");
    printf("Valore finale di j (con mutex): %d\n", j);


    return 0;
}
\end{lstlisting}


\begin{lstlisting}[style=cstyle, caption={File thread.c (Esercizio 2 - Mutex)}, label={lst:ex2_thread}]
#include "function.h"

// Funzione eseguita da ciascun thread
void *thread_function(void *arg) {
    // Recupera l'ID del thread
    int id = *(int *)arg;

    // Ciclo di incremento
    for (int i = 0; i < MAX_NUM; i++) {
        // Acquisisce il lock: se e' gia' bloccato, attende.
        pthread_mutex_lock(&lock);
        // Ora solo un thread alla volta puo' eseguire questa istruzione
        j++;

        // Rilascia il lock, permettendo ad altri thread di entrare
        pthread_mutex_unlock(&lock);
    }
    // la printf stessa dovrebbe essere DENTRO la sezione critica (ma rallenterebbe).
    // printf("Non Protetto: Thread %d ha terminato ciclo. Valore j: %d\n", id, j);

    return NULL;
}
\end{lstlisting}

\subsubsection{Codice Sorgente (con Semaforo)}

\begin{lstlisting}[style=cstyle, caption={File function.h (Esercizio 3 - Semaforo)}, label={lst:ex3_h}]
#ifndef FUNCTION_H
#define FUNCTION_H

#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <semaphore.h> // Include per i semafori POSIX

#define MAX_THREADS 5 // Numero di thread per questo esempio
// MAX_NUM non serve qui, usiamo sleep per simulare lavoro

// Dichiarazione del semaforo globale
extern sem_t sem;

// Prototipo funzione eseguita dai thread
void *thread_function (void *arg);

#endif // FUNCTION_H
\end{lstlisting}

\begin{lstlisting}[style=cstyle, caption={File main.c (Esercizio 3 - Semaforo)}, label={lst:ex3_main}]
#include "function.h"

// Definizione del semaforo globale
sem_t sem;

int main() {
    pthread_t thread_id[MAX_THREADS];
    int thread_args[MAX_THREADS]; // Array per passare l'ID ai thread

    // Inizializza il semaforo
    // Arg 1: Indirizzo del semaforo
    // Arg 2: 0 se il semaforo e' condiviso tra thread dello stesso processo,
    //        != 0 se condiviso tra processi (non trattato qui)
    // Arg 3: Valore iniziale del semaforo (posti disponibili)
    if (sem_init(&sem, 0, 2) != 0) { // Permette a 2 thread di entrare
        perror("Errore nell'inizializzazione del semaforo");
        return 1;
    }
    printf("Semaforo inizializzato a 2.\n");

    // Creazione dei thread
    printf("Creazione di %d thread...\n", MAX_THREADS);
    for (int i = 0; i < MAX_THREADS; i++) {
        thread_args[i] = i;
        if (pthread_create(&thread_id[i], NULL, thread_function, &thread_args[i]) != 0) {
            perror("Errore nella creazione del thread");
            sem_destroy(&sem); // Distrugge il semaforo prima di uscire
            return 1;
        }
    }

    // Attesa della terminazione dei thread
    printf("Attesa terminazione thread...\n");
    for (int i = 0; i < MAX_THREADS; i++) {
        if (pthread_join(thread_id[i], NULL) != 0) {
            perror("Errore nell'attesa del thread (join)");
            sem_destroy(&sem); // Tenta comunque di distruggere il semaforo
            return 1;
        }
    }

    // Distruzione del semaforo
    if (sem_destroy(&sem) != 0) {
        perror("Errore nella distruzione del semaforo");
        // Potrebbe indicare che qualche thread e' ancora bloccato? O errore di cleanup.
    } else {
        printf("Semaforo distrutto.\n");
    }
    printf("\nTutti i thread hanno terminato.\n");

    return 0;
}
\end{lstlisting}

\begin{lstlisting}[style=cstyle, caption={File thread.c (Esercizio 3 - Semaforo)}, label={lst:ex3_thread}]
#include "function.h"

// Funzione eseguita da ciascun thread
void *thread_function(void *arg) {
    // Recupera l'ID del thread
    int id = *(int *)arg;

    printf("Thread %d: in attesa di entrare in sezione critica (sem_wait)...\n", id);

    // Tenta di decrementare il semaforo.
    // Se sem > 0, decrementa e procede.
    // Se sem <= 0, il thread si blocca qui finche' sem non > 0.
    sem_wait(&sem);

    // Al massimo 2 thread possono essere qui contemporaneamente
    printf("Thread %d: ENTRATO in sezione critica.\n", id);
    sleep(2); // Simula un lavoro che richiede tempo all'interno della sezione critica
    printf("Thread %d: USCENDO dalla sezione critica (sem_post)...\n", id);

    sem_post(&sem);

    printf("Thread %d: ha terminato.\n", id);
    return NULL;
}
\end{lstlisting}
\newpage
\section{Presentazione Risultati}
In questa sezione vengono analizzati gli output ottenuti dall'esecuzione dei tre programmi presentati. L'obiettivo è evidenziare le differenze fondamentali nel comportamento e nel risultato finale dovute all'assenza o alla presenza dei diversi meccanismi di sincronizzazione.

\subsection{Esecuzione Senza Sincronizzazione (Esercizio 1)}
Eseguendo il codice del Listing \ref{lst:ex1_main}, che non utilizza né mutex né semafori, si osserva tipicamente un valore finale della variabile globale `j` significativamente inferiore a quello atteso (10000). L'output esatto può variare ad ogni esecuzione a causa della natura non deterministica dello scheduling dei thread. Questo dimostra chiaramente l'effetto della \textit{race condition}: molti incrementi vengono persi perché i thread leggono e scrivono il valore di `j` in modo sovrapposto e non atomico.

\textit{Output Esempio (può variare):}
\begin{verbatim}
    Creazione di 10 thread...
    Attesa terminazione thread...

    Tutti i thread hanno terminato.
    Valore finale di j (senza sincronizzazione): 6432
\end{verbatim}

\subsection{Esecuzione con Mutex (Esercizio 2)}
L'esecuzione del codice protetto da mutex (Listing \ref{lst:ex2_main}) mostra un comportamento corretto. Il valore finale della variabile `j` raggiunge esattamente il valore atteso di 10000. Questo avviene perché il mutex serializza l'accesso alla sezione critica (`j++`), garantendo che solo un thread alla volta possa eseguire l'incremento. Sebbene corretto, questo approccio può limitare il parallelismo, poiché i thread devono attendere il proprio turno per eseguire anche una singola istruzione.
\textit{Output Esempio:}
\begin{verbatim}
    Mutex inizializzato.
    Creazione di 10 thread...
    Attesa terminazione thread...
    Mutex distrutto.

    Tutti i thread hanno terminato.
    Valore finale di j (con mutex): 10000
\end{verbatim}

\subsection{Esecuzione con Semaforo (Esercizio 3)}
L'esempio con il semaforo (Listing \ref{lst:ex3_main}) non mira a calcolare un valore finale condiviso, ma a dimostrare come limitare l'accesso concorrente a una sezione critica. In questo caso, il semaforo è inizializzato a 2. Osservando l'output, si noterà che al massimo due thread alla volta stamperanno il messaggio "ENTRATO in sezione critica" prima che uno di essi stampi "USCENDO dalla sezione critica". Gli altri thread rimarranno in attesa sulla `sem\_wait` finché uno dei due thread all'interno non esegue `sem\_post`. Questo illustra come un semaforo possa gestire l'accesso a un pool limitato di risorse (in questo caso, "slot" per eseguire la sezione critica).

\textit{Output Esempio (l'ordine può variare, ma mai più di 2 "ENTRATO" senza un "USCENDO" intermedio):}
\begin{verbatim}
    Semaforo inizializzato a 2.
    Creazione di 5 thread...
    Thread 0: in attesa di entrare in sezione critica (sem_wait)...
    Thread 0: ENTRATO in sezione critica.
    Thread 1: in attesa di entrare in sezione critica (sem_wait)...
    Thread 1: ENTRATO in sezione critica.
    Thread 2: in attesa di entrare in sezione critica (sem_wait)...
    Thread 3: in attesa di entrare in sezione critica (sem_wait)...
    Thread 4: in attesa di entrare in sezione critica (sem_wait)...
    Attesa terminazione thread...
    Thread 0: USCENDO dalla sezione critica (sem_post)...
    Thread 0: ha terminato.
    Thread 2: ENTRATO in sezione critica.
    Thread 1: USCENDO dalla sezione critica (sem_post)...
    Thread 1: ha terminato.
    Thread 3: ENTRATO in sezione critica.
    Thread 2: USCENDO dalla sezione critica (sem_post)...
    Thread 2: ha terminato.
    Thread 4: ENTRATO in sezione critica.
    Thread 3: USCENDO dalla sezione critica (sem_post)...
    Thread 3: ha terminato.
    Thread 4: USCENDO dalla sezione critica (sem_post)...
    Thread 4: ha terminato.
    Semaforo distrutto.

    Tutti i thread hanno terminato.
\end{verbatim}


\section{Conclusione}
Gli esperimenti condotti hanno dimostrato l'importanza fondamentale dei meccanismi di sincronizzazione nella programmazione concorrente. L'assenza di sincronizzazione (Esercizio 1) porta inevitabilmente a race condition e a risultati errati quando più thread accedono a risorse condivise modificabili. \\
\noindent
L'utilizzo di un \textbf{mutex} (Esercizio 2) ha risolto il problema della race condition garantendo la mutua esclusione nell'accesso alla variabile condivisa `j`. Il risultato finale è stato corretto, dimostrando l'efficacia del mutex per proteggere sezioni critiche dove è richiesta un'esclusività stretta (un solo thread alla volta). Tuttavia, questo avviene al costo di una potenziale riduzione del parallelismo effettivo, poiché i thread sono costretti a serializzare l'accesso alla risorsa protetta. \\
\noindent
L'utilizzo di un \textbf{semaforo} contatore (Esercizio 3) ha mostrato un diverso tipo di controllo sulla concorrenza. Invece di garantire l'accesso esclusivo, ha permesso a un numero limitato (due, in questo caso) di thread di accedere contemporaneamente alla sezione critica simulata. Questo approccio è utile quando si dispone di un pool limitato di risorse o si desidera controllare il grado di parallelismo in una certa parte del codice, senza necessariamente imporRe una serializzazione completa come fa il mutex. \\
\noindent
In sintesi, la scelta tra mutex e semaforo (o altri meccanismi come condition variables, read-write locks, etc.) dipende specificamente dal problema di sincronizzazione che si deve risolvere:
\begin{itemize}
    \item Usare \textbf{mutex} per garantire \textit{mutua esclusione} stretta su una risorsa o sezione critica (accesso a uno alla volta).
    \item Usare \textbf{semafori} (contatori) per gestire l'accesso a un \textit{pool di risorse} (N alla volta) o per implementare \textit{schemi di segnalazione e sincronizzazione} più complessi tra thread (come produttore-consumatore o attesa di completamento).
\end{itemize}
La comprensione e l'applicazione corretta di questi strumenti sono essenziali per sviluppare software multithreaded robusto, efficiente e privo di errori di concorrenza.



\end{document}